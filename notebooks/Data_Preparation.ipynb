{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Data preparation of the TechDebt dataset. Concretely, from the following tables:\n",
    "- GIT_COMMITS\n",
    "- GIT_COMMITS_CHANGES\n",
    "- JIRA_ISSUES\n",
    "- SONAR_ANALYSIS\n",
    "- SONAR_ISSUES\n",
    "- SONAR_MEASURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and packages\n",
    "# Miscellaneous libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import collections\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "os.getcwd()\n",
    "os.chdir( '../src/features')\n",
    "from tracking import track\n",
    "from preparation_data import delete_na, analyse_categorical_variables, one_hot_encoding, message_length,change_commits_to_authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the path of the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "track(\"Defining path of the data files\")\n",
    "# Define the path of the data files\n",
    "path1 = '../../data/raw/'\n",
    "path2 = \"../data/raw/\"\n",
    "path_git_commits = path1 + 'GIT_COMMITS.csv'\n",
    "path_git_commits_changes = path2 + 'GIT_COMMITS_CHANGES.csv'\n",
    "path_jira_issues = path1 + 'JIRA_ISSUES.csv'\n",
    "path_sonar_analysis = path1 + 'SONAR_ANALYSIS.csv'\n",
    "path_sonar_issues = path1 + 'SONAR_ISSUES.csv'\n",
    "path_sonar_measures = path1 + 'SONAR_MEASURES.csv'\n",
    "\n",
    "# Ensure the input file exist\n",
    "assert os.path.isfile(path_git_commits), f'{path_git_commits} not found. Is it a file?'\n",
    "assert os.path.isfile(\"../\"+path_git_commits_changes), f'{path_git_commits_changes} not found. Is it a file?'\n",
    "assert os.path.isfile(path_jira_issues), f'{path_jira_issues} not found. Is it a file?'\n",
    "assert os.path.isfile(path_sonar_analysis), f'{path_sonar_analysis} not found. Is it a file?'\n",
    "assert os.path.isfile(path_sonar_issues), f'{path_sonar_issues} not found. Is it a file?'\n",
    "assert os.path.isfile(path_sonar_measures), f'{path_sonar_measures} not found. Is it a file?'\n",
    "track(\"Finishing defining path of the data files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "track(\"Reading files\")\n",
    "# Read the files\n",
    "git_commits_changes = spark.read.csv(path_git_commits_changes,header=True).toPandas()\n",
    "git_commits = pd.read_csv(path_git_commits)\n",
    "jira_issues = pd.read_csv(path_jira_issues)\n",
    "sonar_analysis = pd.read_csv(path_sonar_analysis)\n",
    "sonar_issues = pd.read_csv(path_sonar_issues)\n",
    "sonar_measures = pd.read_csv(path_sonar_measures)\n",
    "track(\"Finishing reading files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define selected variables\n",
    "In the following section we are only selecting the useful variables for the project. The election process has been studied previusly, in the Data Understanding step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables of interest for each dataframe\n",
    "git_commits_changes_names = ['COMMIT_HASH','DATE','LINES_ADDED','LINES_REMOVED']\n",
    "git_commits_names = ['PROJECT_ID','COMMIT_HASH','AUTHOR','AUTHOR_DATE','AUTHOR_TIMEZONE','COMMIT_MESSAGE']\n",
    "jira_issues_names = ['HASH']\n",
    "sonar_analysis_names = ['PROJECT_ID','ANALYSIS_KEY','REVISION']\n",
    "sonar_issues_names = ['CREATION_ANALYSIS_KEY','SEVERITY','STATUS','EFFORT','MESSAGE','START_LINE','END_LINE','CLOSE_ANALYSIS_KEY']\n",
    "sonar_measures_names = ['analysis_key','complexity' ,'cognitive_complexity', 'coverage', 'duplicated_blocks', 'duplicated_files', \n",
    "                        'duplicated_lines_density', 'violations','blocker_violations','critical_violations','major_violations','minor_violations','info_violations','false_positive_issues','open_issues','reopened_issues','confirmed_issues', 'sqale_debt_ratio','code_smells','bugs','reliability_rating','vulnerabilities','security_rating','files', 'comment_lines_density']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select variables of interest\n",
    "git_commits_changes = git_commits_changes[git_commits_changes_names]\n",
    "git_commits = git_commits[git_commits_names]\n",
    "jira_issues = jira_issues[jira_issues_names]\n",
    "sonar_analysis = sonar_analysis[sonar_analysis_names]\n",
    "sonar_issues = sonar_issues[sonar_issues_names]\n",
    "sonar_measures = sonar_measures[sonar_measures_names]\n",
    "track(\"Finishing selecting variables of interest for each dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "track(\"Starting defining numercial types\")\n",
    "# Select columns of interest\n",
    "dtypes = ['uint8','int16', 'int32', 'int64', 'float16', 'float32', 'float64', 'object']\n",
    "dtypes_num = dtypes[:-1]\n",
    "track(\"Finishing defining numercial types\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NA values\n",
    "Deleting all NA values from the tables by using the global function implemented above delete_na()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "track(\"Starting analysing NA values from all tables\")\n",
    "tables = [sonar_measures, sonar_issues, sonar_analysis, jira_issues,git_commits, git_commits_changes]\n",
    "[sonar_measures, sonar_issues, sonar_analysis, jira_issues,git_commits, git_commits_changes] = delete_na(tables, dtypes)\n",
    "sonar_measures = sonar_measures.reset_index(drop = True)\n",
    "sonar_issues = sonar_issues.reset_index(drop = True)\n",
    "sonar_analysis = sonar_analysis.reset_index(drop = True)\n",
    "jira_issues = jira_issues.reset_index(drop = True)\n",
    "git_commits = git_commits.reset_index(drop = True)\n",
    "git_commits_changes = git_commits_changes.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, in the GIT_COMMITS table, we also find rows that contain the value \"No Author\" in the AUTHOR column.\n",
    "As we cannot know if all those commits come from an unique unidentified person or from multiple ones, we decided to eliminate such rows, as seen in the Data Quality task, they represent a minor percentage of the table length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows that contain missing authors and reseting the DF index.\",\n",
    "git_commits = git_commits.drop(git_commits[git_commits.AUTHOR == \"No Author\"].index)\n",
    "git_commits = git_commits.reset_index(drop= True)\n",
    "track(\"Finishing analysing NA values from all tables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Values\n",
    "The next step is to analyse the categorical variables and encoding them.\n",
    "For the SONAR_MEASURES, JIRA_ISSUES, SONAR_ANALYSIS table (add more if necessary) there are not categorical varibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------+------------------+-----------------------------------------------+\n",
      "|  Table name  | Variable name | Number of levels |                     Types                     |\n",
      "+--------------+---------------+------------------+-----------------------------------------------+\n",
      "| SONAR_ISSUES |    SEVERITY   |        5         | ['INFO' 'MINOR' 'MAJOR' 'CRITICAL' 'BLOCKER'] |\n",
      "| SONAR_ISSUES |     STATUS    |        1         |                   ['CLOSED']                  |\n",
      "+--------------+---------------+------------------+-----------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "track(\"Starting analysing categorical variables\")\n",
    "table_names = [\"SONAR_ISSUES\"]\n",
    "variable_names = [\"SEVERITY\", \"STATUS\"]\n",
    "dataframes = [sonar_issues]\n",
    "analyse_categorical_variables(table_names, variable_names, dataframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen in the chunk above, the SEVERITY and STATUS variables have 5 and 1 levels respectively. In our case, we have performed the One-hot encoding for the SEVERITY variable. For the STATUS variable, efore deleting all NA, there was the OPENED level. However, all rows with an OPENED status contained NA, which means that for this variable we only have the CLOSED level. \n",
    "When joining the tables, we will calulate the mean of each types each author has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonar_issues = one_hot_encoding(sonar_issues, \"SEVERITY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonar_issues = one_hot_encoding(sonar_issues, \"STATUS\")\n",
    "track(\"Finishing analysing categorical variables from all tables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MESSAGE and COMMIT_MESSAGE variables\n",
    "In the following section, we will encode the MESSAGE and COMMIT_MESSAGE variables for the SONAR_ISSUES table and GIT_COMMITS table respectively. For those variables, we will calulate the length of the message for each issue/commit, and reassigning the column with that new value instead of the text from the original message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "track(\"Starting codifying MESSAGE and COMMIT_MESSAGE variables using message_length() function\")\n",
    "message_length(sonar_issues,\"MESSAGE\")\n",
    "message_length(git_commits,\"COMMIT_MESSAGE\")\n",
    "track(\"Finishing codifying MESSAGE and COMMIT_MESSAGE variables using message_length() function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ISSUE_CODE_LENGTH variable\n",
    "\n",
    "In the following cells we will proceed to computate the length mean per issue with the START_LINE and END_LINE variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "track(\"Starting creating ISSUE_CODE_LENGTH variable for SONAR_ISSUES table\")\n",
    "issue_length = []\n",
    "for index, row in sonar_issues.iterrows():\n",
    "    diff = row['END_LINE'] - row['START_LINE']\n",
    "    issue_length.append(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonar_issues = sonar_issues.drop('START_LINE', axis=1)\n",
    "sonar_issues = sonar_issues.drop('END_LINE', axis=1)\n",
    "sonar_issues['ISSUE_CODE_LENGTH'] = issue_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DISCARDING THE DATES COLUMNS AS THEY WON'T BE FINALLY USED FROM THE GIT TABLES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "git_commits = git_commits.drop(\"AUTHOR_DATE\", axis = 1)\n",
    "git_commits_changes = git_commits_changes.drop(\"DATE\",axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To execute the Join operation, first we will focus on the Sonar tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to execute the groupby functions, first we need to associate each commit to\n",
    "# an author in the sonar_complete table. To do so, a dictionary of commit- author will be created.\n",
    "commit_author_dict = {}\n",
    "for i in range(len(git_commits)):\n",
    "    commit_author_dict[git_commits[\"COMMIT_HASH\"][i]] = git_commits[\"AUTHOR\"][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "track(\"Starting joining SONAR tables\")\n",
    "# Joining SONAR_ANALYSIS with SONAR_ISSUES\n",
    "sonar_issues_complete_1 = pd.merge(sonar_issues, sonar_analysis, left_on='CREATION_ANALYSIS_KEY', right_on='ANALYSIS_KEY', how='inner')\n",
    "sonar_issues_complete_2 = pd.merge(sonar_issues, sonar_analysis, left_on='CLOSE_ANALYSIS_KEY', right_on='ANALYSIS_KEY', how='inner')\n",
    "sonar_issues_complete_1 = sonar_issues_complete_1.drop(['CREATION_ANALYSIS_KEY','CLOSE_ANALYSIS_KEY','ANALYSIS_KEY'], axis=1)\n",
    "sonar_issues_complete_2 = sonar_issues_complete_2.drop(['CREATION_ANALYSIS_KEY','CLOSE_ANALYSIS_KEY','ANALYSIS_KEY'], axis=1)\n",
    "sonar_issues_complete = pd.concat([sonar_issues_complete_1, sonar_issues_complete_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting duplicated rows\n",
    "sonar_issues_complete = sonar_issues_complete.drop_duplicates()\n",
    "sonar_issues_complete = sonar_issues_complete.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining SONAR_ANALYSIS with SONAR_MEASURES\n",
    "sonar_measures_complete = pd.merge(sonar_measures, sonar_analysis, left_on = \"analysis_key\", right_on = \"ANALYSIS_KEY\", how = \"inner\")\n",
    "sonar_measures_complete = sonar_measures_complete.drop([\"analysis_key\",\"ANALYSIS_KEY\"],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting duplicated rows\n",
    "sonar_measures_complete = sonar_measures_complete.drop_duplicates()\n",
    "sonar_measures_complete = sonar_measures_complete.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonar_issues_complete = change_commits_to_authors(sonar_issues_complete,\"REVISION\",commit_author_dict)\n",
    "sonar_measures_complete = change_commits_to_authors(sonar_measures_complete,\"REVISION\",commit_author_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once both tables contain the author info, we proceeed to aggrupate by such value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SONAR_ISSUES \n",
    "# First we add a new dummy column containg all 1s that will allow us to compute the total number of issues per author afterwards.\n",
    "sonar_issues_complete[\"N_ISSUES\"] = [1 for i in range(len(sonar_issues_complete))]\n",
    "# Then, a dictionary is created indicating which aggregation function will be used for each column.\n",
    "# In general, the mean will be used except for variables referencing counts.\n",
    "issues_ag_fun = {}\n",
    "for col in sonar_issues_complete.select_dtypes(include=dtypes_num).columns:\n",
    "    issues_ag_fun[col] = 'mean'\n",
    "\n",
    "counts = [\"MESSAGE\",\"BLOCKER\",\"CRITICAL\",\"INFO\",\"MAJOR\",\"MINOR\",\"N_ISSUES\"]\n",
    "for col in counts:\n",
    "    issues_ag_fun[col] = 'sum'\n",
    "# Then, the number of differents projects for an authors is also added.\n",
    "issues_ag_fun[\"PROJECT_ID\"] = 'nunique'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonar_issues_grouped = sonar_issues_complete.groupby('Author').agg(issues_ag_fun)\n",
    "sonar_issues_grouped = sonar_issues_grouped.rename(columns={\"PROJECT_ID\":\"N_PROJECTS_I\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we perform the same operation for the sonar measures table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SONAR_MEASURES\n",
    "# First we add a new dummy column containg all 1s that will allow us to compute the total number of measures per author afterwards.\n",
    "sonar_measures_complete[\"N_MEASURES\"] = [1 for i in range(len(sonar_measures_complete))]\n",
    "# Then, a dictionary is created indicating which aggregation function will be used for each column.\n",
    "# In general, the mean will be used except for variables referencing counts.\n",
    "measures_ag_fun = {}\n",
    "for col in sonar_measures_complete.select_dtypes(include=dtypes_num).columns:\n",
    "    measures_ag_fun[col] = 'mean'\n",
    "\n",
    "measures_ag_fun[\"N_MEASURES\"] = 'sum'\n",
    "# Then, the number of differents projects for an authors is also added.\n",
    "measures_ag_fun[\"PROJECT_ID\"] = 'nunique'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonar_measures_grouped = sonar_measures_complete.groupby('Author').agg(measures_ag_fun)\n",
    "sonar_measures_grouped = sonar_measures_grouped.rename(columns={\"PROJECT_ID\":\"N_PROJECTS_M\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, the merge between the two tables is executed.\n",
    "sonar_complete_grouped = sonar_measures_grouped.join(sonar_issues_grouped, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a left join has been performed, the NA values represent authors that have been analyzed but no issues\n",
    "# where found on such analysis, thus those NA are in reality 0.\n",
    "sonar_complete_grouped=sonar_complete_grouped.fillna(0)\n",
    "track(\"Finishing joining SONAR tables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will proceed with the commit tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "track(\"Starting joining COMMIT tables\")\n",
    "# First, we join the git_commits with the git_commit_changes table.\n",
    "git_complete =  pd.merge(git_commits, git_commits_changes, left_on='COMMIT_HASH', right_on='COMMIT_HASH', how='inner')\n",
    "git_complete = git_complete.drop(\"COMMIT_HASH\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we add a new dummy column containg all 1s that will allow us to compute the total number of commits with changes per author afterwards.\n",
    "git_complete[\"N_COMMITS\"] = [1 for i in range(len(git_complete))]\n",
    "# Then, a dictionary is created indicating which aggregation function will be used for each column.\n",
    "# In general, the mean will be used except for variables referencing counts.\n",
    "commits_ag_fun = {}\n",
    "for col in git_complete.select_dtypes(include=dtypes_num).columns:\n",
    "    commits_ag_fun[col] = 'mean'\n",
    "\n",
    "# Then, the number of differents projects for an authors is also added.\n",
    "commits_ag_fun[\"PROJECT_ID\"] = 'nunique'\n",
    "commits_ag_fun[\"N_COMMITS\"] = 'sum'\n",
    "# Regarding the timezone, the most frequent one (in case an author has multiple ones) is added.\n",
    "commits_ag_fun[\"AUTHOR_TIMEZONE\"] = lambda x:x.value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "git_complete_grouped = git_complete.groupby('AUTHOR').agg(commits_ag_fun)\n",
    "git_complete_grouped = git_complete_grouped.rename(columns={\"PROJECT_ID\":\"N_PROJECTS_C\"})\n",
    "git_complete_grouped[\"AUTHOR_TIMEZONE\"] = git_complete_grouped['AUTHOR_TIMEZONE']/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUTHOR_TIMEZONE</th>\n",
       "      <th>COMMIT_MESSAGE</th>\n",
       "      <th>N_COMMITS</th>\n",
       "      <th>N_PROJECTS_C</th>\n",
       "      <th>complexity</th>\n",
       "      <th>cognitive_complexity</th>\n",
       "      <th>coverage</th>\n",
       "      <th>duplicated_blocks</th>\n",
       "      <th>duplicated_files</th>\n",
       "      <th>duplicated_lines_density</th>\n",
       "      <th>...</th>\n",
       "      <th>EFFORT</th>\n",
       "      <th>MESSAGE</th>\n",
       "      <th>BLOCKER</th>\n",
       "      <th>CRITICAL</th>\n",
       "      <th>INFO</th>\n",
       "      <th>MAJOR</th>\n",
       "      <th>MINOR</th>\n",
       "      <th>ISSUE_CODE_LENGTH</th>\n",
       "      <th>N_ISSUES</th>\n",
       "      <th>N_PROJECTS_I</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adrian Crum</th>\n",
       "      <td>0.0</td>\n",
       "      <td>181.068966</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>3157.625000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>213.250000</td>\n",
       "      <td>37.875000</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>190.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adrian Nistor</th>\n",
       "      <td>0.0</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9545.000000</td>\n",
       "      <td>5528.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alan Gates</th>\n",
       "      <td>0.0</td>\n",
       "      <td>149.763446</td>\n",
       "      <td>15823</td>\n",
       "      <td>1</td>\n",
       "      <td>103180.343750</td>\n",
       "      <td>84767.937500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5706.406250</td>\n",
       "      <td>697.718750</td>\n",
       "      <td>19.040625</td>\n",
       "      <td>...</td>\n",
       "      <td>34.389637</td>\n",
       "      <td>164858.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>959.0</td>\n",
       "      <td>877.0</td>\n",
       "      <td>0.125907</td>\n",
       "      <td>1930.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alex Karasulu</th>\n",
       "      <td>0.0</td>\n",
       "      <td>185.182796</td>\n",
       "      <td>279</td>\n",
       "      <td>1</td>\n",
       "      <td>7195.717391</td>\n",
       "      <td>7854.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>69.586957</td>\n",
       "      <td>5.976087</td>\n",
       "      <td>...</td>\n",
       "      <td>19.350785</td>\n",
       "      <td>13279.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.015707</td>\n",
       "      <td>191.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alexander Shraer</th>\n",
       "      <td>0.0</td>\n",
       "      <td>183.153153</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "      <td>9174.636364</td>\n",
       "      <td>8272.545455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>313.454545</td>\n",
       "      <td>98.545455</td>\n",
       "      <td>5.809091</td>\n",
       "      <td>...</td>\n",
       "      <td>10.838710</td>\n",
       "      <td>1793.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dlaha</th>\n",
       "      <td>0.0</td>\n",
       "      <td>202.800000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10066.000000</td>\n",
       "      <td>5623.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>449.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>184.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecki</th>\n",
       "      <td>0.0</td>\n",
       "      <td>173.161290</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>4473.000000</td>\n",
       "      <td>2839.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2.125000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fpj</th>\n",
       "      <td>0.0</td>\n",
       "      <td>94.906977</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>10111.000000</td>\n",
       "      <td>8916.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>markt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3463.000000</td>\n",
       "      <td>2304.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pjack</th>\n",
       "      <td>0.0</td>\n",
       "      <td>457.775330</td>\n",
       "      <td>227</td>\n",
       "      <td>1</td>\n",
       "      <td>4046.743590</td>\n",
       "      <td>2786.897436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.282051</td>\n",
       "      <td>24.897436</td>\n",
       "      <td>6.771795</td>\n",
       "      <td>...</td>\n",
       "      <td>14.353846</td>\n",
       "      <td>7216.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>244 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  AUTHOR_TIMEZONE  COMMIT_MESSAGE  N_COMMITS  N_PROJECTS_C  \\\n",
       "Adrian Crum                   0.0      181.068966         29             2   \n",
       "Adrian Nistor                 0.0      197.000000          1             1   \n",
       "Alan Gates                    0.0      149.763446      15823             1   \n",
       "Alex Karasulu                 0.0      185.182796        279             1   \n",
       "Alexander Shraer              0.0      183.153153        111             1   \n",
       "...                           ...             ...        ...           ...   \n",
       "dlaha                         0.0      202.800000          5             1   \n",
       "ecki                          0.0      173.161290         31             1   \n",
       "fpj                           0.0       94.906977         43             1   \n",
       "markt                         0.0       68.000000          1             1   \n",
       "pjack                         0.0      457.775330        227             1   \n",
       "\n",
       "                     complexity  cognitive_complexity  coverage  \\\n",
       "Adrian Crum         3157.625000           2008.000000       0.0   \n",
       "Adrian Nistor       9545.000000           5528.000000       0.0   \n",
       "Alan Gates        103180.343750          84767.937500       0.0   \n",
       "Alex Karasulu       7195.717391           7854.000000       0.0   \n",
       "Alexander Shraer    9174.636364           8272.545455       0.0   \n",
       "...                         ...                   ...       ...   \n",
       "dlaha              10066.000000           5623.000000       0.0   \n",
       "ecki                4473.000000           2839.750000       0.0   \n",
       "fpj                10111.000000           8916.000000       0.0   \n",
       "markt               3463.000000           2304.000000       0.0   \n",
       "pjack               4046.743590           2786.897436       0.0   \n",
       "\n",
       "                  duplicated_blocks  duplicated_files  \\\n",
       "Adrian Crum              213.250000         37.875000   \n",
       "Adrian Nistor            440.000000        105.000000   \n",
       "Alan Gates              5706.406250        697.718750   \n",
       "Alex Karasulu            159.000000         69.586957   \n",
       "Alexander Shraer         313.454545         98.545455   \n",
       "...                             ...               ...   \n",
       "dlaha                    449.000000        120.000000   \n",
       "ecki                      61.000000         24.000000   \n",
       "fpj                      384.000000        107.000000   \n",
       "markt                     74.000000         25.000000   \n",
       "pjack                    121.282051         24.897436   \n",
       "\n",
       "                  duplicated_lines_density  ...     EFFORT   MESSAGE  BLOCKER  \\\n",
       "Adrian Crum                       7.600000  ...  40.000000     190.0      0.0   \n",
       "Adrian Nistor                     6.200000  ...   0.000000       0.0      0.0   \n",
       "Alan Gates                       19.040625  ...  34.389637  164858.0     16.0   \n",
       "Alex Karasulu                     5.976087  ...  19.350785   13279.0      2.0   \n",
       "Alexander Shraer                  5.809091  ...  10.838710    1793.0      0.0   \n",
       "...                                    ...  ...        ...       ...      ...   \n",
       "dlaha                             6.600000  ...   4.666667     184.0      0.0   \n",
       "ecki                              2.125000  ...   0.000000       0.0      0.0   \n",
       "fpj                               5.000000  ...   0.000000       0.0      0.0   \n",
       "markt                             3.900000  ...   0.000000       0.0      0.0   \n",
       "pjack                             6.771795  ...  14.353846    7216.0      1.0   \n",
       "\n",
       "                  CRITICAL  INFO  MAJOR  MINOR  ISSUE_CODE_LENGTH  N_ISSUES  \\\n",
       "Adrian Crum            0.0   0.0    3.0    2.0           0.000000       5.0   \n",
       "Adrian Nistor          0.0   0.0    0.0    0.0           0.000000       0.0   \n",
       "Alan Gates            75.0   3.0  959.0  877.0           0.125907    1930.0   \n",
       "Alex Karasulu          9.0   0.0  116.0   64.0           0.015707     191.0   \n",
       "Alexander Shraer       0.0   0.0   11.0   20.0           0.064516      31.0   \n",
       "...                    ...   ...    ...    ...                ...       ...   \n",
       "dlaha                  0.0   0.0    1.0    2.0           0.000000       3.0   \n",
       "ecki                   0.0   0.0    0.0    0.0           0.000000       0.0   \n",
       "fpj                    0.0   0.0    0.0    0.0           0.000000       0.0   \n",
       "markt                  0.0   0.0    0.0    0.0           0.000000       0.0   \n",
       "pjack                  5.0   4.0   59.0   61.0           0.000000     130.0   \n",
       "\n",
       "                  N_PROJECTS_I  \n",
       "Adrian Crum                1.0  \n",
       "Adrian Nistor              0.0  \n",
       "Alan Gates                 1.0  \n",
       "Alex Karasulu              1.0  \n",
       "Alexander Shraer           1.0  \n",
       "...                        ...  \n",
       "dlaha                      1.0  \n",
       "ecki                       0.0  \n",
       "fpj                        0.0  \n",
       "markt                      0.0  \n",
       "pjack                      1.0  \n",
       "\n",
       "[244 rows x 40 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then, the mergr between the sonar and the commits author tables is performed.\n",
    "complete_table = git_complete_grouped.join(sonar_complete_grouped, how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lastly, the final dataframe is written in the suitable folder.\n",
    "complete_table.to_csv(\"../../data/processed/model_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
